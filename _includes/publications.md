
## <i class="fa fa-chevron-right"></i> Publications

Representative publications that I am a primary author on are
<span style='background-color: #ffffd0'>highlighted.</span><br>
[<a href="https://scholar.google.com/citations?user=DclFbLwAAAAJ&hl">Google Scholar</a>]
<br>
<br>

<h4>First Author and Corresponding Author</h4>
<table class="table table-hover">
<tr id="tr-shi22_interspeech">
  <td>
    <li>
      <font size=2>
      <u>Hao&nbsp;Shi</u>, Longbiao&nbsp;Wang, Sheng&nbsp;Li, Jianwu&nbsp;Dang, and Tatsuya&nbsp;Kawahara.<br>
      Monaural speech enhancement based on spectrogram decomposition for convolutional neural network-sensitive feature extraction.&nbsp;<em><a href='' target='_blank'>[ref]</a> </em><br>
      In Proc. INTERSPEECH, pp., 2022.<br>
      </font>
    </li>
  </td>
</tr>
    
<tr id="tr-song22_interspeech" >
  <td>
    <li>
      <font size=2>
      Tongtong&nbsp;Song, Qiang&nbsp;Xu, Meng&nbsp;Ge, Longbiao&nbsp;Wang, <u>Hao&nbsp;Shi</u>, Yongjie&nbsp;Lv, Yuqin&nbsp;Lin, and Jianwu&nbsp;Dang.<br>
      Language-specific Characteristic Assistance for Code-switching Speech Recognition.&nbsp;<em><a href='' target='_blank'>[ref]</a> </em><br>
      In Proc. INTERSPEECH, pp., 2022.<br> 
      <font color=Blue>(Corresponding author)</font>
      </font>
    </li>
  </td>
</tr>
    
<tr id="tr-xu22_interspeech" >
  <td>
    <li>
      <font size=2>
      Qiang&nbsp;Xu, Tongtong&nbsp;Song, Longbiao&nbsp;Wang, <u>Hao&nbsp;Shi</u>, Yuqin&nbsp;Lin, Yongjie&nbsp;Lv, Meng&nbsp;Ge, Qiang&nbsp;Yu, and Jianwu&nbsp;Dang.<br>
      Self-Distillation Based on High-level Information Supervision for Compressing End-to-End ASR Model.&nbsp;<em><a href='' target='_blank'>[ref]</a> </em><br>
      In Proc. INTERSPEECH, pp., 2022.<br> 
      <font color=Blue>(Corresponding author)</font>
      </font>
    </li>
  </td>
</tr>    
    
<tr id="tr-shi21_apsipa">
  <td>
    <li>
      <font size=2>
      <u>Hao&nbsp;Shi</u>, Longbiao&nbsp;Wang, Sheng&nbsp;Li, Cunhang&nbsp;Fan, Jianwu&nbsp;Dang, and Tatsuya&nbsp;Kawahara.<br>
      Spectrograms Fusion-based End-to-end Robust Automatic Speech Recognition.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/APSIPA-2021.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc. APSIPA ASC, pp.438--442, 2021.<br>
      </font>
    </li>
  </td>
</tr>

<tr id="tr-qiang21_iconip">
  <td>
    <li>
      <font size=2>
      Luya&nbsp;Qiang, <u>Hao&nbsp;Shi</u>, Meng&nbsp;Ge, Haoran&nbsp;Yin, Nan&nbsp;Li, Longbiao&nbsp;Wang, Sheng&nbsp;Li, and Jianwu&nbsp;Dang.<br>
      Speech Dereverberation Based on Scale-aware Mean Square Error Loss.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/SaSD.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc of ICONIP, pp.55--63, 2021.<br> 
      <font color=Blue>(Joint first author, equal contribution)</font>
      </font>
    </li>
  </td>
</tr>

<tr id="tr-yin21_iconip">
  <td>
    <li>
      <font size=2>
      Haoran&nbsp;Yin, <u>Hao&nbsp;Shi</u>, Longbiao&nbsp;Wang, Luya&nbsp;Qiang, Sheng&nbsp;Li, Meng&nbsp;Ge, Gaoyan&nbsp;Zhang, and Jianwu&nbsp;Dang.<br>
      Simultaneous Progressive Filtering-based Monaural Speech Enhancement.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/iconip2021-yin.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc. ICONIP, pp.213--221, 2021.<br>
      <font color=Blue>(Joint first author, equal contribution)</font>
      </font>
    </li>
  </td>
</tr>
    
<tr id="tr-shi20_interspeech">
  <td>
    <li>
      <font size=2>
      <u>Hao&nbsp;Shi</u>, Longbiao&nbsp;Wang, Sheng&nbsp;Li, Chenchen&nbsp;Ding, Meng&nbsp;Ge, Nan&nbsp;Li, Jianwu&nbsp;Dang, and Hiroshi&nbsp;Seki.<br>
      Singing Voice Extraction with Attention-Based Spectrograms Fusion.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/Wed-1-11-1.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc. INTERSPEECH, pp.2412--2416, 2020.<br>
      </font>
    </li>
  </td>
</tr>

<tr id="tr-9054661">
  <td>
    <li>
      <font size=2>
      <u>Hao&nbsp;Shi</u>, Longbiao&nbsp;Wang, Meng&nbsp;Ge, Sheng&nbsp;Li, and Jianwu&nbsp;Dang.<br>
      Spectrograms Fusion with Minimum Difference Masks Estimation for Monaural Speech Dereverberation.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/0007539.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc. ICASSP, pp.7539--7543, 2020.<br>
      </font>
    </li>
  </td>
</tr>
</table>





<h4>Co-author</h4>
<table class="table table-hover">
<tr id="tr-ge19_interspeech" >
  <td>
    <li>
      <font size=2>
      Meng&nbsp;Ge, Longbiao&nbsp;Wang, Nan&nbsp;Li, <u>Hao&nbsp;Shi</u>, Jianwu&nbsp;Dang, and Xiangang&nbsp;Li.<br>
      Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement.&nbsp;<em><a href='https://github.com/hshi-speech/resume/blob/main/pdf/1477.pdf' target='_blank'>[ref]</a> </em><br>
      In Proc. INTERSPEECH, pp.3151--3157, 2019.<br>
      </font>
    </li>
  </td>
</tr>

</table>

